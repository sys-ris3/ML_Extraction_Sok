[net]
batch=1
subdivisions=1

height=7
width=7
channels=1228

[linear_transform]
units=1024

[add_mask]

[batchnorm]
bn_bias=1
nhwc=1

[activation]
activation=relu6

[avgpool]
nhwc=1

#[dropout] inference dropout layer do nothing

[add_mask]

